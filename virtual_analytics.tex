% $Id: template.tex 11 2007-04-03 22:25:53Z jpeltier $

\documentclass{vgtc}                          % final (conference style)
%\documentclass[review]{vgtc}                 % review
%\documentclass[widereview]{vgtc}             % wide-spaced review
%\documentclass[preprint]{vgtc}               % preprint
%\documentclass[electronic]{vgtc}             % electronic version

\let\ifpdf\relax

%% Uncomment one of the lines above depending on where your paper is
%% in the conference process. ``review'' and ``widereview'' are for review
%% submission, ``preprint'' is for pre-publication, and the final version
%% doesn't use a specific qualifier. Further, ``electronic'' includes
%% hyperreferences for more convenient online viewing.

%% Please use one of the ``review'' options in combination with the
%% assigned online id (see below) ONLY if your paper uses a double blind
%% review process. Some conferences, like IEEE Vis and InfoVis, have NOT
%% in the past.

%% Figures should be in CMYK or Grey scale format, otherwise, colour 
%% shifting may occur during the printing process.

%% These three lines bring in essential packages: ``mathptmx'' for Type 1 
%% typefaces, ``graphicx'' for inclusion of EPS figures. and ``times''
%% for proper handling of the times font family.

\usepackage{mathptmx}
\usepackage{graphicx}
\usepackage{times}
\usepackage{url}

%% We encourage the use of mathptmx for consistent usage of times font
%% throughout the proceedings. However, if you encounter conflicts
%% with other math-related packages, you may want to disable it.

%% If you are submitting a paper to a conference for review with a double
%% blind reviewing process, please replace the value ``0'' below with your
%% OnlineID. Otherwise, you may safely leave it at ``0''.
\onlineid{0}

%% declare the category of your paper, only shown in review mode
\vgtccategory{Research}

%% allow for this line if you want the electronic option to work properly
\vgtcinsertpkg

%% In preprint mode you may define your own headline.
%\preprinttext{To appear in an IEEE VGTC sponsored conference.}

\usepackage[export]{adjustbox}

\usepackage{enumitem}
\setlist{noitemsep} % or \setlist{noitemsep} to leave space around whole list

\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{gray}{rgb}{0.4,0.4,0.4}
\definecolor{darkblue}{rgb}{0.0,0.0,0.6}
\definecolor{cyan}{rgb}{0.0,0.6,0.6}

\lstdefinelanguage{XML}
{
  morestring=[b]",
  morestring=[s]{>}{<},
  morecomment=[s]{<?}{?>},
  stringstyle=\color{black},
  basicstyle=\small,
  showstringspaces=false,
  tabsize=4,
  identifierstyle=\color{darkblue},
  keywordstyle=\color{cyan},
  morekeywords={xmlns,version,rdf,rdfs,my,owl}
  columns=flexible,
  breaklines=true,
  breakatwhitespace=true% list your attributes here
}

\newcommand*\mvb[1]{\textcolor{red}{#1}}

%% Paper title.

\title{Interactive Visual Analytics of Molecular Data in Immersive Environments via a Semantic Definition of the Content and the Context}

%% This is how authors are specified in the conference style

%% Author and Affiliation (single author).
%%\author{Roy G. Biv\thanks{e-mail: roy.g.biv@aol.com}}
%%\affiliation{\scriptsize Allied Widgets Research}

%% Author and Affiliation (multiple authors with single affiliations).
%%\author{Roy G. Biv\thanks{e-mail: roy.g.biv@aol.com} %
%%\and Ed Grimley\thanks{e-mail:ed.grimley@aol.com} %
%%\and Martha Stewart\thanks{e-mail:martha.stewart@marthastewart.com}}
%%\affiliation{\scriptsize Martha Stewart Enterprises \\ Microsoft Research}

%% Author and Affiliation (multiple authors with multiple affiliations)
\author{Mikael Trellet\thanks{e-mail: trellet@limsi.fr}\\ %
      \parbox{1.4in}{\scriptsize \centering Venise group \\ LIMSI-CNRS }%
\and Nicolas F\'{e}rey\thanks{e-mail: ferey@limsi.fr}\\ %
     \parbox{1.4in}{\scriptsize \centering Venise group \\ LIMSI-CNRS }%
\and Marc Baaden\thanks{e-mail: baaden@smplinux.de}\\ %
     \parbox{1.4in}{\scriptsize \centering LBT \\ IBPC-CNRS}
\and Patrick Bourdot\thanks{e-mail: bourdot@limsi.fr}\\ %
     \parbox{1.4in}{\scriptsize \centering Venise group \\ LIMSI-CNRS }}%

%% A teaser figure can be included as follows, but is not recommended since
%% the space is now taken up by a full width abstract.
%\teaser{
%  \includegraphics[width=1.5in]{sample.eps}
%  \caption{Lookit! Lookit!}
%}

%% Abstract section.
\abstract{
Bringing together, in a unique immersive environment, visualization and analysis of scientific and complex data requires a thorough approach in order to fulfill scientists' specific expectations. Such an approach needs to consider the highly heterogeneous nature of data, the dynamic interactions between experts and data, and the large amount of data involved in scientific studies.
Whereas small and static scientific datasets can quickly be deciphered thanks to standard immersive tools such as 3D visualization software packages, bigger and dynamic datasets exceed the analytical capacity of these tools, requiring an efficient platform for their manipulation. Through the example of the structural biology field we discuss the need for an approach based on a high-level definition of the content (scientific data) and the context (immersive environments and interfaces). Our design is illustrated by a platform for dynamic and intelligent representation of data to the user. This classification \mvb{((Which classification??))} will provide new ways to interact with the data via intelligent and direct links \mvb{((What type of links??))}. This approach is based on the semantic definition of all the concepts manipulated in the virtual environment, either abstract or concrete, which allows for an adaptive and interactive experience of both visualization and analysis.
} % end of abstract

%% ACM Computing Classification System (CCS). 
%% See <http://www.acm.org/class/1998/> for details.
%% The ``\CCScat'' command takes four arguments.

\CCScatlist{ 
  \CCScat{Computer Graphics}{I.3.7}{Three-Dimensional Graphics and Realism}{Virtual Reality}
}

%% Copyright space is enabled by default as required by guidelines.
%% It is disabled by the 'review' option or via the following command:
% \nocopyrightspace

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% START OF THE PAPER %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%% The ``\maketitle'' command must be the first command after the
%% ``\begin{document}'' command. It prepares and prints the title block.

%% the only exception to this rule is the \firstsection command
\firstsection{Introduction}

\maketitle

%% \section{Introduction} 


With the increasing complexity of scientific data that experts have to manipulate, the need for platforms capable of handling the intricate data flow is strong. The issue is particularly pressing in the field of structural biology. One central building block in this field, the numerical simulation process, is now able to deal with very large and heterogeneous molecular structures. These molecular assemblies may be composed of several million particles and consist of many different types of molecules, including a biologically realistic environment. This overall complexity raises the need to go beyond common visualization solutions and move towards integrated exploration systems where visualization and analysis can be merged. 

These integrated systems must be able to deal with heterogeneous data, rendering them in a condensed working environment for the expert's needs.
Immersive environments play an important role in this context, providing both a better comprehension of the 3-dimensional structure of molecules, and offering new interaction techniques to reduce the number of data manipulations executed by the experts.

A few studies took advantage of recent developments in Virtual Reality to enhance some structural biology tasks. Visualization is the first and most obvious task that was improved through new adaptive stereoscopic screens and immersive environments plunging experts into the very center of their molecules~\cite{van2000immersive,stone_immersive_2010,odonoghue_visualization_2010,hirst2014molecular}. Structure manipulations during specific docking experiments have been improved thanks to the use of haptic devices and audio feedbacks to drive a simulation~\cite{ferey_multisensory_2009}. Despite these studies, no specific development has been made to setup an immersive platform where the expert could manipulate data coming from different sources to accelerate and improve the development of new hypotheses.

Today, the main workflow that experts follow in structural biology studies compartmentalizes the visualization of data and their analysis into two different and independent sequential tasks based on separate tools. This separation can be partly explained by the significant differences between the data handled by the 3D visualization software packages and the analytical tools.

On one side, 3D visualization solutions such as PyMol~\cite{delano_pymol_2002}, VMD~\cite{humphrey_vmd:_1996} or UnityMol~\cite{lv2013game} explore and manipulate 3D structure coordinates composing the molecular complex that will be displayed. The scene seen by the user is composed of 3D objects reporting the overall shape of a particular molecule and its environment at a particular state. This scene is static if we are interested in only one state of a given molecule, but is often dynamic when a whole simulated trajectory of conformational changes over time is considered.

Analysis tools, on the other side, handle raw numbers, vectors and matrices in various formats and dimensions, from various input sources depending on the analysis pipeline used to generate them. Their outputs are graphical representations of trends or comparisons between parameters or properties in 1 to N dimensions formatted in a way that experts can quickly understand and use such information to guide their hypotheses.
During the process that tries to decipher a scientific mechanism, and as we highlighted previously, experts constantly move from visualization tools to analysis tools and vice versa, wasting a precious amount of time along the way.

A major improvement of tools available today would bring into play a scenario where the 3D visualization of a molecular event is coupled to monitoring the evolution of analytical properties, e.g. sub-elements such as distance variations and progression of simulation parameters, into a single working environment. The expert would be able to see any action performed in one space (either 3D visualization or analysis) with a coherent graphical impact on the second space to filter or highlight the parameter or sub-ensemble of objects targeted by the expert.

\begin{figure}[htb]
  \centering
  \includegraphics[width=\linewidth, frame]{figures/interactive_selection.pdf}
  \caption{3D visualization and analytical plot of a protein into two different spaces in the same environment. Any subset of points selected in the analytical space is instantaneously highlighted in the visualization space.}
  \label{interactive_selection}
\end{figure}

Immersive environments favor the combination of heterogeneous information sources and provide several ways to merge data and processes for a particular task. The combination of heterogeneous information brings a complexity not at the context level anymore but rather at the content level. This complexity needs to be addressed in order to propose a fully-functional immersive environment where scientists will have the possibility to visualize, analyze and interact with their data.

There is a need to link heterogeneous data around an homogeneous framework where each object or group of objects can be related to the parameters or properties that define them. These links will first enable to access an object via its parameters, then, conversely, it will enable access to parameters by the object itself. Beyond information access, an interaction of the user with the graphical representation of either the object in the 3D visualization space, or the parameters in the analytical space, will have an impact in the reciprocal space as illustrated in the figure \ref{interactive_selection}.

A database defined by a high-level representation of all the data represents an efficient way to mix visualization and analysis. By classifying knowledge, it is possible to create direct links between individuals and properties, then setup automatic retrievals of data each time an expert would need it.

The semantic definition of the application field is sufficient to implement dynamic links between visual and analytical properties but does not allow for a specific way to interact with the data. As a consequence, we extended the definition of the structural biology content to the immersive context in which the platform will be used.
By doing so, we were able to combine information from both the expert knowledge and the user context in order to define intelligent interactions during an immersive working session.

% Bringing closer visualization and graphic analysis of scientific data while adding an interactive dimension is extensively studied in the field of Visual Analytics (VA). VA focuses on the graphical deciphering of complex data through interactive visual interfaces. This field stands on the border of several other fields such as the scientific visualization, the human-computer interaction and the perception with the aim to emphasize information that were previously hidden when using classic techniques from the cited fields in a partitioned way.

\section{Semantic definition of the platform}

In Computer Science, knowledge representation is often associated to the notion of ontology. An ontology is defined as a structured and hierarchical ensemble of concepts and relationships allowing to define a partial or a whole field. An ontology must be comprehensible by both  computer systems and humans. Indeed, an ontology often needs to be integrated into automatic processes setup by experts of a specific field, not always familiar with the computing side of the ontology.

Ontologies must allow the classification of any specific value or information into a pre-defined scheme \mvb{((ou schematic, mais schema n'existe pas en anglais))} as instances of elements of this scheme. It plays the role of a set of grammatical rules for a language made of data.
% For instance, a very simple ontology consisting of the two concepts "Atom" and "Charge" linked by a possessive relationship as illustrated in supplementary material.
% If any atom is added to a database defined by this ontology, an instance of the concept "Atom" will be created and a value of charge will be added to the property "Charge". The atom and the value will be linked and it will be possible to access them by searching either for the instance or for the property.

\subsection{State of the Art}

The semantic description of content through ontologies in immersive environments has been reported as a very efficient way to setup artificial intelligent systems ~\cite{Wiebusch:2015aa}, to design new VR applications~\cite{kleinermann2005designing} or to implement multimodal interactions~\cite{irawati2005semantic}. Although these developments allowed for a very interesting usage of semantic descriptions in immersive environments, they aim for a generic definition of either the content or the context. Therefore such approaches lack either the expert field knowledge or the interactive possibilities, both required to setup intelligent interactions.

On the application side, the setup of ontologies in order to standardize knowledge in scientific fields has undergone an important and spontaneous growth at the end of the 90s~\cite{schulze-kremer_ontologies_2002}.

Bioinformatics, tightly anchored with structural biology, uses ontologies for a long time. The most significant example is the fast-growing genomic field where it became quickly impossible to handle data flow without a proper and standardized organization of the data~\cite{schuurman_ontologies_2008}. \textit{Gene Ontology}~\cite{ashburner_gene_2000} was created to regroup genomic data into a uniform format and database. Today it is one of the most cited ontologies. 
% Several biological databases or organizations like UniProtKB\footnote{\url{http://www.uniprot.org/uniprot/}} or the \textit{Open Biomedical Ontologies}~\cite{smith2007obo}, provide ways to access data or ontologies under RDF or OWL format to allow their use in expert tools or specific pipelines.

Only very few expert software packages in structural biology have based their development on the usage of ontologies. DIVE~\cite{rysavy_dive:_2014} and Avogadro~\cite{hanwell2012avogadro} appear both as exceptions, implementing, in different ways, a semantic description of the data they are manipulating. Avogadro is using the Chemical Markup Language (CML) for its semantic capability and adds a description layer on top of the data the software is dealing with. However, no ontologies are set up and there no use is made of the reasoning capabilities of this semantic description. 

DIVE offers the possibility to create on-the-fly ontologies and datasets based on the input data. This data representation allows a common data model that the software libraries will use. Then, creation of links between data values and concepts are possible and the different DIVE components (analyses, 3D visualization, etc.) are able to query them at any moment. Beyond value, links and relationships between the dataset elements can be queried. DIVE further implements a powerful and generic ontology creator directly depending on the type of the input data. However, DIVE is limited to quite a simple reasoning on the ontology, based on the multiple inheritance notion. It extends the basic oriented object philosophy found in JAVA, C\# or VB.NET, for instance. Consequently, only some ontological relationships are available: \textit{is-a}, \textit{contains}, \textit{is-part-of} and \textit{bound-by}. There is no notion of cardinality or logical operators to define the concept classes. Our needs go slightly beyond and we identified several requirements that our approach should satisfy.


\subsection{Formalism choice}

The formalism of knowledge representation used in our approach must address the following three rules to properly fit our platform needs:

\begin{enumerate}
  \item Hierarchical data representation via concepts and properties
  \item Reasoning possibility in order to extend the ontology or the dataset ruled by the ontology
  \item Efficient query time on the data to stay within interaction time
\end{enumerate}

Several formalisms exist to create ontologies and use them to define databases. A comparison of these formalisms can be found in the table \ref{formalisms_comparison}.

\begin{table*}[t]
  % \centering
\begin{tabular}{l|*{5}{c|}}
Formalism          & Domain description & Reasoning on knowledge & Big data management & Efficient & Implementation flexibility \\
\hline
Conceptual Graphs  & X & X & - & X & -  \\
Semantic networks  & X & - & X & X & -  \\
Classical logics   & X & X & X & X & -  \\
Description logics & X & X & X & X & -  \\
\end{tabular}
\caption{Comparison of different knowledge representation formalisms with respect to key criteria.}
  \label{formalisms_comparison}
\end{table*}


We chose to use the Semantic Web approach in order to setup our own ontology. 
The Semantic Web has been created by the \textit{World Wide Web Consortium} under the lead of Tim Berners-Lee, with the aim to share semantic data on the web~\cite{berners2001semantic}. It is broadly used by the biggest web companies to uniformly store and share data. It belongs to the family of the Description logics that use the notions of \textit{concepts, roles} and \textit{individuals}. 
The \textit{concepts} are represented by the sub-ensemble of elements in a specific universe, the \textit{roles} are the links between the elements and the \textit{individuals} are the elements of the universe~\cite{}\mvb{((previous citation missing))}. In our previous example, "Atom" and "Charge" would be \textit{concepts}, "has-a" a \textit{role} and the oxygen an \textit{individual}, as an instance of the \textit{concept} "Atom".
% Each layer of the Semantic Webs (ontology, experimental data, querying process, etc.) have been associated to a language or a format. The different layers and their associated formats are described in the figure~\ref{web_semantic_hierarchy}. 

\subsection{Semantic Web Layers}

The Resource Description Framework (RDF) is the basic model of Semantic Webs. It is a graph-based model aiming to describe in a formal way resources and their associated metadata. It is based on a knowledge representation from triples, a triple being the smallest knowledge division in RDF. Every data description is then an ensemble of triples including (\textit{subject}, \textit{predicate}, \textit{object})~\cite{godel1999bach}.

The \textit{subject} is the resource described, the \textit{predicate} represents a property attached to the resource and the \textit{object} may represent a resource or a data (being a value of the attached property). Any resource is identified by an URI (Uniform Resource Identifier) whereas a data is anonymous since it can be duplicated (numerical value, string, etc.). An example of a triple could be:
\\
(\textit{http://ontology.org/\#Pierre}, \textit{http://ontology.org/\#age}, \textit{xsd:int\^{}\^{}26})
\\
\mvb{((Dans l'exemple precedent on ne comprend pas bien les ontology.org et xsd:int je trouve))}
RDF has been quickly extended by a semantic layer in a model called RDF Schema (RDFS)~\cite{brickley2004rdf}. It defines classes, sub-classes, properties and sub-properties from which RDF resources will inherit. 

% \begin{figure}[htb]
%   \centering
%   \includegraphics[width=.5\linewidth]{figures/web_semantic_hierarchy.png}
%   \caption{Hierarchical schema of the Semantic Webs multiple layer architecture}
%   \label{web_semantic_hierarchy}
% \end{figure}


% It permits the setup of relationships between high-level concepts and then extract relationships at the individual level. Included in the semantic layer, RDFS also provides the possibility to restrain the \textit{subjects} classes (\textit{rdfs:domain}) and \textit{objects} classes/datatypes (\textit{rdfs:range}) for a specific property used in RDF as a \textit{predicate}.
% For instance, the 2 following triples:
% \begin{lstlisting}[language=XML]
% <my:Protein>	<my:contains>	<my:Lysine>
% <my:contains>	<rdfs:range>	<my:Amino-acid>
% \end{lstlisting}
% \noindent
% will indirectly imply the following statement:
% \begin{lstlisting}[language=XML]
% <my:Lysine>	<my:is-a>	<my:Amino-acid>
% \end{lstlisting}
% \noindent

The semantic layer provided by RDFS can be complemented by another model named OWL. OWL is a computer standard, supports Semantic Web ontologies, grammatically defines RDF data to ensure their coherency, and sets up a semantic framework. It is complementary to the RDFS even if it goes further in terms of reasoning possibilities and resource description. More expressive than RDFS, OWL adds specific relationships based on logical links between properties or classes. It is then possible to add symmetry, transitivity, similarity or cardinality information on top of concept relationships.
Then \mvb{((THen?.. tu veux dire with OWL?))}, these triples:
\begin{lstlisting}[language=XML]
<my:is-composed-of>	<my:is-a>	<owl:TransitiveProperty>
<my:Protein>		<my:is-composed-of>	<my:Amino-acid>
<my:Amino-acid>		<my:is-composed-of>	<my:Atom>
\end{lstlisting}
will indirectly imply the following statement:
\begin{lstlisting}[language=XML]
<my:Protein>	<my:is-composed-of>	<my:Atom>
\end{lstlisting}

A crucial part of our immersive analytics platorm requirements was to be able to access the data defined by the ontology and stored as RDF triples. Efficient access can be achieved via SPARQL, a query language and protocol used to access databases based on RDF triples. SPARQL not only allows to access data but also to edit, add or remove them. 
% The access is done thanks to a specific endpoint provided as an URL and accessible by most of software libraries handling RDF data. 
SPARQL is closely related to SQL in its functioning, implementing the SELECT, FROM and WHERE keywords to build a query. 
% One of the difference with the SQL is the processing of queries. This is a 2-steps process where the first one is a research of matching patterns between the query and the database triples then a projection step where only the variables queries will be returned. 
Several operations are possible on the final results including SORT, JOIN, DISTINCT in order to filter or sort the results. Examples of SPARQL queries and their output is \mvb{Is or is not??} provided as supplementary material.

\section{Architecture}

The different layers introduced in the previous section need to be set up in order to create a fully integrated semantic layer around the immersive environment. Once this semantic definition is achieved, a core module will interface user actions and data manipulations within the immersive environment.

\subsection{Ontology for the modeling of structural biology concepts}

An OWL-based ontology was implemented as core of the platform, thereby creating a broad description of concepts an expert would have to manipulate during visualization and analysis activities. We previously mentioned that several bio-ontologies already exist. We extended one of them, a bio-ontology describing amino-acids and their biophysical and geometrical properties\footnote{\url{http://bioportal.bioontology.org/ontologies/AMINO-ACID}}.
Each component structuring molecular complexes and each associated property coming from various common bio-informatics tools have been systematically defined in our ontology. However, since needs may vary, we designed this ontology such that it could easily be updated and enriched with new concepts.
Our ontology has been designed around five categories, addressing five different parts of our platform:

\begin{itemize}
  \item \textbf{Biomolecular knowledge} - Gather field-related concepts and objects in structural biology 
  \item \textbf{3D structure representation} - Gather concepts related to the representation and visualization of 3D molecular complexes
  \item \textbf{2D data representation} - Gather concepts related to the representation of numerical analyses and their results
  \item \textbf{3D interactions} - Gather concepts related to the interactions in 3D environnements
  \item \textbf{2D interactions} - Gather concepts related to the interactions in 2D environnements
\end{itemize}

The separation of the categories does not induce the absence of relationships between any two categories. For instance, "Atom" belongs to the \textbf{Biomolecular knowledge} category but is directly linked to the "Sphere" concept from \textbf{3D structure representation}. The whole network of connections will then permit to reason on the ontology in order to support the advanced interactivity level required in Visual Analytics \mvb{((premiere apparence du terme VA je crois.. est un peu bizarre ici))}.

Concepts and properties among the \textbf{3D structure representation} and \textbf{2D data representation} categories gather the graphical elements that allow for the representation of the \textbf{Biomolecular knowledge} category. Shape, colors but also graph types are notions defined in these two categories. 
% It is worth noting that analytical concepts are defined by graphical or abstract elements that play a role in the creation and visualization of an analytical result. However, we voluntarily chose to not define the different calculations and analyses of molecular simulation data because of their high complexity and their heterogeneous nature between the specialized tools. This does not mean that they will not be used among the platform, it is only not relevant to include them in the ontology.

In addition to the biomolecular concepts and representations previously cited, we also defined every concept around the interaction between the user and the data he will directly or indirectly manipulate. These interactions include commands proposed by most of the visualization software packages and analysis tools.

\subsection{Molecular database}

Once we set up our ontology, it was possible to feed the database by adding biological information gathered by the expert. The new information has to fit the vocabulary and classification defined by the rules present in the ontology in order to be adequately stored in the database.

The description of a molecular system is constructed from the analysis of any biological information that can be described by a character chain or a value and that corresponds to a concept or property identified in the ontology. Each information will be exhaustively gathered in the RDF database as triples. Within the scope of our study, we focused on numerical molecular simulations. These simulations output time series of static snapshots of the molecular system at a regular time step. The Hamiltonian of the simulated model will drive the system towards specific states that experts try to decipher in order to understand underlying molecular mechanisms. The whole simulation creates a trajectory where each state, at a precise time, is associated to a snapshot. Our ontology defines a snapshot by the \textit{Model} concept. A \textit{Model} gathers all the atom coordinates of the molecular system at a defined time step. In order to distinguish the different components of a system, these components are identified by \textit{Chain}, another concept of our ontology. Each \textit{Chain} in the system is composed of a sequence of \textit{Residues} (also known as \textit{Amino-acids} in proteins). The different inference rules present in the ontology save us to specify all the links between the different hierarchical components of a specific \textit{Model} explicitly. As a result, a \textit{Residue} that belongs to a specific \textit{Chain} will be automatically associated to the corresponding \textit{Model} where the \textit{Chain} appears.
Some triples of our database can \mvb{((Are, are not??))} be provided in supplementary material.

Every geometrical property (position, angle, distance, etc.), physicochemical property (solvent accessibility, partial charge, bond, etc.) or analytical property (interaction energy, RMSD, temperature, etc.) is then integrated in the database and associated to individuals created from 3D structures (Model/Chain/Residue/Atom) for each step of the simulation. As a reminder, any individual is an instance of concepts defined in the ontology. Individuals and their properties form the population of the molecular database.

\subsection{Interrogation and queries for the direct interaction}

Once all data has been integrated in the RDF database, it is necessary to setup an interrogation system able to retrieve the data for visualization and processing following interaction events in the working space. Our implementation of the query system mainly relies on the usage of SPARQL, as introduced before, and provides several ways to address the different needs of our platform. The richness and flexibility of SPARQL queries  allowed us to design a keyword to command interpretation engine that aims to transform a list of keywords into a comprehensive application command triggering an action in the working space.

One of the most widely used interactive techniques in immersive environments is the vocal command. Based on a vocal recognition process, it consists in translating a sentence or a group of words said by the user into an application command. Vocal commands have the strong advantage that they can be associated with gestures to express complex multimodal commands. \mvb{((est-ce que c'etait bien le sens de la phrase initiale - que je n'avais pas comprise dans son etat?))}

Most of the actions identified in our platform involve a structural group designated by the expert. These structural groups can be characterized by: identifiers having a biological meaning (residue ids are, by convention, numbered from one extremity of the chain to the other), unique identifiers in the RDF database, or via their properties.
The interpretation of commands vocalized by the expert with natural language using a specific field-related vocabulary requires a representation carrying the complexity of the knowledge and linking the objects targeted by the user to the virtual objects involved in the interaction.

For this purpose, we set up a process that takes as input a vocal command of the user and translates it into an application command for the operating system. This procedure can be divided in three main parts:

\begin{enumerate}
  \item Recognition of keywords from a vocal command
  \item Keyword classification in a decomposed command structure
  \item Creation of the final and operational command
\end{enumerate}

Our conceptualization effort and the use of the ontology mainly focused on the second part. Parts one and three are more implementation oriented and will not be deeply described.

\subsubsection{Keyword recognition}

We are using the keyword spotting capability of Sphinx~\footnote{\url{http://sourceforge.net/projects/cmusphinx/}}, a vocal recognition toolkit, to recognize keywords. Based on a dictionary created from the ontology list of concepts, it aims to detect any word said by the user that would match a word present in the dictionary.

\subsubsection{Keyword classification}

Each keyword recognized in the previous step is assigned to a category. This classification is based on our ontology splitting which identifies five categories of words that can be found in a vocal command, semantically modeled as:

\begin{itemize}
  \item \textbf{Action}
  \item \textbf{Component}
  \item \textbf{Identifier}
  \item \textbf{Property}
  \item \textbf{Representation}
\end{itemize}

This classification is achieved through successive SPARQL queries to the ontology. \textit{Action}, \textit{Component}, \textit{Property} and \textit{Representation} categories have their own concepts and can be identified by a unique word ("Hide", "Chain", "Charged", "Sphere", etc.). At the opposite, the \textit{Identifier} category is linked to a concept instance from the \textit{Component} category. A biological identifier is very likely to be redundant because of the repetition of the molecular system at each time step. Therefore it is mandatory to associate a component with an identifier in the keywords to detect any identifier, and it is necessary that the associated component possesses the identifier in the database to validate the classification. \mvb{((j'ai un peu de mal avec la phrase precedente.. peux-tu etre plus clair/explicite?))}

SPARQL commands use the \textit{ASK} operator to define whether a keyword belongs to a category or not. This operator takes one or several triples and returns a boolean that reflects whether the ensemble of triples is true or not with respect to the database. Some examples of queries can be found below:

\begin{lstlisting}[language=XML]
ASK {my:Hide rdfs:subClassOf my:Action}
ASK {my:Alanine rdfs:subClassOf my:Biological_component}
ASK {my:Cartoon rdfs:subClassOf my:Representation}
ASK {my:Aliphatic rdfs:subClassOf my:Property}
\end{lstlisting}

Reasoning and inference rules are automatically used in SPARQL queries. For instance, the following query:

\begin{lstlisting}[language=XML]
ASK {my:Alanine rdfs:subClassOf my:Biological_component}
\end{lstlisting}
\noindent
will output \textit{true} despite the absence of an explicit direct link between the two concepts (\textit{Alanine} and \textit{Biological\_component}) since \textit{AminoAcid}, \textit{Residue} and \textit{Molecule} are located between the two concepts (see Figure \ref{Fig:alanine_owl}).

\hspace{1cm}

\begin{figure}[!htb]
  \centering
  {\includegraphics[width=\linewidth]{./figures/alanine_to_bio_component_owl}}
    \caption[Extract from OWL ontology for the \textit{Alanine} concept.]{\it Extract from our OWL ontology for the \textit{Alanine} concept.}
  \label{Fig:alanine_owl}
  % \hspace{0.3cm}
\end{figure}

Once each keyword is validated and associated to a category, e.g. identified as a concept of the database (or as an individual for identifiers) and eventually grouped with another keyword, it forms a syntactic group. Each syntactic group carries an information corresponding to a specific part of the application command.

\subsubsection{From vocal command to application command}

In our platform, a vocal command is composed by a succession of syntactic groups linked between them to create an action query to the \mvb{immersive?} platform. It is possible to describe the type of command that was defined in the following manner:

$$action\ [parameter]^+,\ (\ structural\_group\ [identifier]^+\ )^+$$

Syntactic groups between $[]$ are optional, whereas others are mandatory. The $+$ indicates the possibility to have 0, 1 or several occurrences of the syntactic group. Finally, $()$ indicates a bloc of syntactic groups. This command architecture is present in our ontology under the form of pre-required concepts associated to the \textit{Action} concepts. For instance, the action concept \textit{Color} requires a property of \textit{Colors} type and a structural component to work with. These elements of information are then stored in the ontology, rendering them automatically checkable by the engine to detect whether all requirements are fulfilled for a specific action. This feature simpifies the definition of other actions in the ontology as the changes that have to be applied to the engine are minimal, typically either no or minor changes. The checking process will stay the same as long as the action is well-defined within the ontology.

At the same level as for an action, a structural group is always mandatory to trigger a command. \mvb{Selon ta syntaxe, on pourrait avoir une action avec 0 groupes syntactiques, non??} The different ways to obtain a structural sub-ensemble are:

\begin{enumerate}
  \item Component only: every individual that belongs to the concept will be taken into account
  \item Combination of a component and an ensemble of identifiers: \mvb{description missing here??} 
  \item Property only: every individual that possesses the property will be taken into account
  \item Combination of a component and a property: coherency checking between component and property
\end{enumerate}

The structural group always refers to a group of individuals in order to disambiguate the results between the commands. This disambiguation implies that final commands are more complex.
The hierarchical classification between structural components (Model/Chain/Residue/Atom) has a significant impact on the results of a given command. Indeed, the nature of structural components targeted by an action will be compared to the nature of the structural components currently studied. Depending on whether the command individual will be of a higher or lower hierarchical order, the command might trigger an action on a subpart of the displayed scene (for lower classified individuals) or \mvb{((probleme de raccord de cette 2e partie de phrase))} as a scene composition changer (for higher or equal classified individuals).
For instance, if only two models are studied when a vocal command is transmitted, putative amino-acids individually targeted by an action will be the ones that belong to the two displayed models. If the individuals targeted by the command action would have been models, different from the displayed ones, an update of the displayed molecular complexes would have occurred first.

Once the different checks for the command coherency and validity have been carried out, the command is sent to both spaces (visualization and analysis) in order to synchronize the visual results.

\section{Reasoning over semantic data - Scenario}

Our interpretation engine, able to translate a list of vocalized keywords into an application command, provides further possibilities through its semantic-based architecture. The visualization (or analytical) filter directly links an individual and its representations to any user interaction with a structural group, a property or an analytic value in either the visualization or analysis space. It is therefore possible to set up intelligent interactions in the immersive environment and synchronize any action of the expert between his two working spaces.

\subsection{Test case}

To illustrate the full-capacity of our platform, we chose a typical example of a molecular system study. This example sets up a local visualization solution coupled to a distant web server where interactive graphs can be created. Both spaces can be rendered in an immersive environment, either in the same screen space or split on one 3D screen for the visualization and a tablet providing analysis results through a web server. We assume, as it is the case in real studies, that the expert knows the molecular system well and can therefore interact vocally or by selecting elements in one of the spaces.

\begin{figure}[!htb]
  \centering
  {\includegraphics[width=\linewidth,frame]{./figures/scenario_step_1_cropped}}
    \caption[]{{\it On the right, selection of interesting models in the analytical space. The visualization state on the left is synchronized thanks to a SPARQL query in order to display the selected models.}}
  \label{Fig:1st_step}
  % \hspace{0.3cm}
\end{figure}

The first step of our scenario is a query triggered by the analytical space (web server) to retrieve every numerical value that can be represented in a scatter plot. This query will start the connection between the visualization space and the analytical space for the whole session. 
Once the values are gathered, the expert will choose which structural component hierarchy he is interested in and which combination of properties he wants to plot. Several queries will retrieve the property values and the web server graphs library, D3.js\footnote{\url{https://d3js.org/}}, will plot these values. We chose here to focus on the model level and display a simple distance criterion between a reference model and all the models of the studied trajectory.

The expert can select several models of interest, as shown in the first step of figure~\ref{Fig:1st_step}. The selection is synchronized over all previously created scatter plots and will trigger a synchronous visualization of the individuals in the visual space (see second step of figure \ref{Fig:1st_step}).

The expert may then switch to the visualization space and select some elements of the displayed structures he would like to focus on. These sub-elements of the current models will be sent to the analytical space that will ask the expert for the properties to be plotted. Once the choice is made, the selection will be highlighted in the analytical space as shown in the figure \ref{Fig:2nd_step} for a selection of 3 residues.

The selection process can be triggered by a vocal command through our interpretation engine or by a manual selection. 
New graphs can be added at runtime at any moment and are synchronized with the current ones. However, it is important to note that a full synchronization between the visualization and analytical spaces requires the same hierarchy of structural elements to be selected in both spaces. If a new selection is made at a \textit{Model} level, any graphs of lower hierarchy will be reset with the new selected models and the visualization will be reset with the new models at the same time.

\begin{figure}[!htb]
  \centering
  {\includegraphics[width=\linewidth,frame]{./figures/scenario_step_2_cropped}}
    \caption[]{{\it On the left, selection of amino-acids of interest. The analytical space on the right is synchronized thanks to a SPARQL query and proposes analyses adapted to the visualization context to the expert.}}
  \label{Fig:2nd_step}
  % \hspace{0.3cm}
\end{figure}

\subsection{Evaluation}

The evaluation process started from the observation that the systematic evaluation of field-related tasks is rather complicated to set up for four reasons. (1) Usage and nature of the evaluated tools, in particular in molecular visualization, differ between experts. (2) Implementation and adaptation of our developments over a representative sample of the tools is complex and very time-consuming. (3) Our approach is biased since it is based on the execution of expert tasks. (4) In order to apply standard statistic methods for evaluation, it is necessary to gather enough participants, yet the number of experts in our application field is rather limited.

We therefore propose an evaluation method that is more theoretically oriented than empirical: the HTA method (for "Hierarchical Task Analysis")~\cite{annett2003hierarchical}. The HTA method consists in a division of a primary task into several sub-tasks. Each sub-task can be subdivided again until the sub-tasks reach a degree of precision sufficient to have their execution time evaluated accurately.

This method is particularly useful to compare similar tasks performed under different conditions. It allows to evaluate both the task methodology with respect to specific conditions and the performance of the conditions for a specific task. HTA requires only one expert to evaluate the different sub-task execution times.

\section{Conclusion}

We have set up a semantic layer over an immersive environment dedicated to the interactive visualization and analysis of molecular simulation data. This setup was achieved through the implementation of an ontology describing both structural biology and interaction concepts manipulated by the experts during a study process.

Our architecture, built around heterogeneous components, achieves to bring together visualization and analytical spaces thanks to a common ontology-driven module that maintains a perfect synchronization between the different representations of the same elements in the two spaces.

The knowledge provided by the ontology can significantly improve the interactive capability of the platform by proposing contextualized analysis choices to the user, adapted to the types of elements in his current focus. All along the study process, a set of specific analyses, non redundant with the ones already performed, can be interactively chosen to populate the database. A simple definition of analyses in the ontology, adding input and output types, is sufficient to decide whether an analysis is pertinent or not for a precise selection, and whether the resulting values are already present in the database or not.

The reasoning capability of the ontology allowed us to develop an efficient interpretation engine that can transform a vocal command composed of keywords into an application command. This framework paves the way for a multimodal supervision tool that would use the high-level description of the manipulated elements, as well as the heterogeneous interaction natures, to merge inputs and create intelligent and complex commands in line with the work of M.E. Latoschik~\cite{Wiebusch:2015aa} or~\cite{gutierrez2005semantics}.
The RDF/RDFS/OWL model coupled to the SPARQL language allows to enunciate rules of inference, which is particularly important for the decision taking process in collaborative contexts. In these contexts, two users may trigger a multimodal command, in a conjoint way, that can be difficult to interpret without proper rules. An effort would then have to be made to integrate these rules in a future supervisor of the input modality, based on the semantic model, taken users as elements of modality in a multimodal interaction.

Our approach opens the way to a new generation of scientific applications. We illustrated our developments through the field of structural biology but it is worth to note that the generic nature of the Semantic Web allows to extend our developments to most scientific fields where a tight coupling between visualization and analyses is important. 


%% if specified like this the section will be ommitted in review mode
% \acknowledgements{
% The authors wish to thank A, B, C. This work was supported in part by
% a grant from XYZ.}

\bibliographystyle{abbrv}
%%use following if all content of bibtex file should be shown
%\nocite{*}
\bibliography{virtual_analytics}

% \section{Supplementary material}

% \subsection{SPARQL query example}

% \begin{lstlisting}[language=SPARQL]
% SELECT ?x ?id
% FROM <http://my_database.com> 
% WHERE {
%   ?y my:is-composed-of ?x .
%   ?y rdf:type my:Chain .
%   ?y my:chain_id "B" .
%   ?x my:res_id ?id
% }
% \end{lstlisting}
% \noindent

% \begin{center}
%  \begin{tabular}{|c | c|} 
%  \hline
%  ?x & ?id \\ [0.5ex] 
%  \hline
%  RES\_11 & 1 \\ 
%  RES\_12 & 2 \\
%  RES\_13 & 3 \\
%  RES\_14 & 4 \\
%  RES\_15 & 5 \\
%  \hline
% \end{tabular}
% \end{center}
% \noindent

% \subsection{Database triples}

% \begin{lstlisting}[language=XML]

% <owl:ObjectProperty rdf:about="&my;hasSize">
%     <rdf:type rdf:resource="&owl;FunctionalProperty"/>
%     <rdfs:domain rdf:resource="&my;AminoAcid"/>
%     <rdfs:range rdf:resource="&my;Size"/>
%     <rdfs:subPropertyOf rdf:resource="&my;has_property"/>
% </owl:ObjectProperty>

% <owl:DatatypeProperty rdf:about="&my;chain_id">
%     <rdfs:range rdf:resource="&xsd;int"/>
% </owl:DatatypeProperty>

% <rdf:Description rdf:about="my:ATOM_36795">
%   <my:atom_id rdf:datatype="#int">125</my:atom_id>
%   <my:time_frame rdf:datatype="#int">190</my:time_frame>
%   <rdf:type rdf:resource="my:Atom"/>
%   <my:pos_z rdf:datatype="#double">22.33</my:pos_z>
%   <my:atom_type>CB</my:atom_type>
%   <my:pos_x rdf:datatype="#double">21.86</my:pos_x>
%   <my:uniq_id rdf:datatype="#int">36795</my:uniq_id>
%   <my:pos_y rdf:datatype="#double">31.6</my:pos_y>
%   <my:belongs_to rdf:resource="my:RES_3622"/>
% </rdf:Description>

% \end{lstlisting}

\end{document}

